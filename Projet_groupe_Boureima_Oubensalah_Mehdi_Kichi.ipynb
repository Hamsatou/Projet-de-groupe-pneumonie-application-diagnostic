{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flask_blog.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "stVgTSOmLx_a"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NFTTPQHIsvD"
      },
      "source": [
        "! unzip NORMAL_test.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nyr_JjRJJ46Q"
      },
      "source": [
        "! unzip PNEUMONIA_test.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2K2u64_Is1k"
      },
      "source": [
        "!unzip PNEUMONIA.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgdZCWnJJ4_F"
      },
      "source": [
        "! unzip NORMAL.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGCUn4wuJ5Db"
      },
      "source": [
        "! unzip PNEUMONIA_train.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEvOg0iDnx-P"
      },
      "source": [
        "! unzip NORMAL_train.zip  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hojNrFXQU24W"
      },
      "source": [
        "!git clone https://github.com/vb100/Pneumonia-X-Rays-of-Human-Lungs-AI-project"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBgmq7h6bgCt"
      },
      "source": [
        "## Libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE3VjF6wwofa"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import os, stat, time\n",
        "from os.path import dirname as up\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.layers.core import Dense, Flatten, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.regularizers import l2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.convolutional import *\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import SGD\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from vb100_utils import *\n",
        "from shutil import copyfile\n",
        "import shutil\n",
        "import glob\n",
        "from PIL import Image\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ifplwhEySqa"
      },
      "source": [
        "\"\"\"\n",
        "!pip install sklearn\n",
        "!pip install -U matplotlib\n",
        "!pip install Pillow\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7UV9GaibmZq"
      },
      "source": [
        "## data pipelining "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq7Ft0pdyZVp"
      },
      "source": [
        "# CONSTANTS FOR DIRECTORIES\n",
        "TRAIN_DIR = 'Pneumonia-X-Rays-of-Human-Lungs-AI-project/data/train'\n",
        "VALID_DIR = 'Pneumonia-X-Rays-of-Human-Lungs-AI-project/data/val'\n",
        "TEST_DIR = 'Pneumonia-X-Rays-of-Human-Lungs-AI-project/data/test'\n",
        "l_DIRS = [TRAIN_DIR, VALID_DIR, TEST_DIR]\n",
        "POSITIVE_CLASS = 'NORMAL'\n",
        "ABSTRACT_CLASS = 'PNEUMONIA'\n",
        "\n",
        "# CONSTANTS FOR IMAGE PARAMETERS\n",
        "INPUT_W = 1200 # pixels\n",
        "INPUT_H = 900  # pixels\n",
        "DIVIDER = 3.6\n",
        "INPUT_DIM = (int(INPUT_W/DIVIDER), int(INPUT_H/DIVIDER), 1)\n",
        "BATCH_SIZE_TRAIN = 64\n",
        "BATCH_SIZE_TEST = 64 \n",
        "BATCH_SIZE_VALID = 16\n",
        "NORMALIZER = 1./255\n",
        "IMAGE_FORMAT = 'jpeg'\n",
        "# Output Info\n",
        "print('Image dimmensions for CNN = {}'.format(INPUT_DIM))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vWRnTqKt6iL"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "train_normal=os.listdir('Pneumonia-X-Rays-of-Human-Lungs-AI-project/data/train/NORMAL/')\n",
        "\n",
        "plt.suptitle('Normal Lungs')\n",
        "for i in range(4,7):\n",
        "    img =train_normal[i]\n",
        "    #img = str(img)\n",
        "    img = load_img('Pneumonia-X-Rays-of-Human-Lungs-AI-project/data/train/NORMAL/'+img)\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol19XnKXuPGs"
      },
      "source": [
        "import seaborn as sns\n",
        "train_pneumonia=os.listdir('Pneumonia-X-Rays-of-Human-Lungs-AI-project/data/train/BACTERIA/')\n",
        "sns.barplot(x=['Normal','Pneumonia'],y=[len(train_normal),len(train_pneumonia)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLUHIM_SypDF"
      },
      "source": [
        "if abstract_class_exists(ABSTRACT_CLASS, l_DIRS):\n",
        "  \n",
        "    structure_origin_data(l_DIRS, IMAGE_FORMAT, POSITIVE_CLASS)\n",
        "\n",
        "classes = classes_for_each_set(l_DIRS)\n",
        "\n",
        "print('Catched classes for the model:\\n{}'.format(classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR-QwioyytkS"
      },
      "source": [
        "# Generating and Plot Image Data from Train Set\n",
        "TRAIN_BATCHES = ImageDataGenerator(rescale=NORMALIZER).\\\n",
        "    flow_from_directory(TRAIN_DIR,\n",
        "    color_mode='grayscale',\n",
        "    target_size=INPUT_DIM[0:2],\n",
        "    classes=classes['TRAIN'],\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    batch_size=BATCH_SIZE_TRAIN)\n",
        "\n",
        "imgs, labels = next(TRAIN_BATCHES)  # <-- Extracting image matrixes and labels\n",
        "plots(imgs, titles=labels)          # <-- Plot Images with labels\n",
        "#train_imgs = rgb_to_grayscale(imgs) # <-- Convert RGB images to Grayscale ones by Tensorflow\n",
        "#train_labels = labels\n",
        "# Generating and Plot Image Data from Test Set\n",
        "TEST_BATCHES = ImageDataGenerator(rescale=NORMALIZER).\\\n",
        "    flow_from_directory(TEST_DIR,\n",
        "    color_mode='grayscale',\n",
        "    target_size=INPUT_DIM[0:2],\n",
        "    classes=classes['TEST'],\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    batch_size=BATCH_SIZE_TEST)\n",
        "\n",
        "imgs, labels = next(TEST_BATCHES)   # <-- Extracting image matrixes and labels\n",
        "plots(imgs, titles=labels)          # <-- Plot Images with labels\n",
        "#test_imgs = rgb_to_grayscale(imgs)  # <-- Convert RGB images to Grayscale ones by Tensorflow\n",
        "#test_labels = labels\n",
        "\n",
        "# Generating and Plot Image Data from Validation Set\n",
        "VAL_BATCHES = ImageDataGenerator(rescale=NORMALIZER).\\\n",
        "    flow_from_directory(VALID_DIR,\n",
        "    color_mode='grayscale',\n",
        "    target_size=INPUT_DIM[0:2],\n",
        "    classes=classes['VALIDATION'],\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    batch_size=BATCH_SIZE_VALID)\n",
        "\n",
        "imgs, labels = next(VAL_BATCHES)   # <-- Extracting image matrixes and labels\n",
        "plots(imgs, titles=labels)         # <-- Plot Images with labels\n",
        "#val_imgs = rgb_to_grayscale(imgs)  # < -- Convert RGB images to Grayscale ones by Tensorflow\n",
        "#val_labels = labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KDFRjMfez0D"
      },
      "source": [
        "# Output of Generators\n",
        "for data_batch, label_batch in TRAIN_BATCHES:\n",
        "    print('data batch shape = {}'.format(data_batch.shape))\n",
        "    print('labels batch shape = {}'.format(label_batch.shape))\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdzdsPFabtCd"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7-Yiaeje7I6"
      },
      "source": [
        "from keras import regularizers\n",
        "# Build the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (5, 5), input_shape=(INPUT_DIM)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((3, 3)))\n",
        "model.add(Conv2D(128, (4, 4))) \n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(512, (3, 3))) \n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(512, (3, 3))) \n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(512, (3, 3))) \n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(512, (2, 2))) \n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten()) \n",
        "model.add(Dense(512, kernel_regularizer=regularizers.l2(0.02))) \n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(3)) \n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85vCFh0dfEHr"
      },
      "source": [
        "# Define an optimizer for the model\n",
        "opt = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "#opt = SGD(lr=0.01, decay=1e-6, momentum=0.85, nesterov=True)\n",
        "#opt = RMSprop(lr=0.001, rho=0.8, epsilon=None, decay=0.0)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpisYS2pfXWl"
      },
      "source": [
        "print('steps_per_epoch={}'.format(int(5215 / BATCH_SIZE_TRAIN)))\n",
        "print('validation_steps={}'.format(int(624 / BATCH_SIZE_TEST)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nfd_wSBefc9P"
      },
      "source": [
        "h = model.fit_generator(\n",
        "    TRAIN_BATCHES,\n",
        "    steps_per_epoch=len(TRAIN_BATCHES),\n",
        "    validation_data=TEST_BATCHES,\n",
        "    validation_steps=len(TEST_BATCHES),\n",
        "    epochs=35,\n",
        "    verbose=2)\n",
        "# Parameters meanings:\n",
        "# steps_per_epoch = number_of_images / batch_size = 5215 / 64 = 82:\n",
        "# --- Total number of steps (batches of samples) to yield from generator before declaring one \n",
        "#     epoch finished and starting the next epoch. It should typically be equal to the number \n",
        "#     of unique samples of your dataset divided by the batch size.\n",
        "# Verbose:\n",
        "# -- 0 (quiet): you just get the total numbers of tests executed and the global result\n",
        "# -- 1 (default): you get the same plus a dot for every successful test or a F for every failure\n",
        "# -- 2 (verbose): you get the help string of every test and the result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm1dKVC-bzmd"
      },
      "source": [
        "## Ploting learning curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsRWeJucfgOc"
      },
      "source": [
        "# Plot Result Graph for Accuracy, Loss and Validation\n",
        "def plot_model_result(model):\n",
        "\t'''\n",
        "\t\t-- model : Keras model.\n",
        "\t'''\n",
        "\n",
        "\trcParams['figure.figsize'] = 14, 4 # Set plot size\n",
        "\n",
        "\t# Plot #1\n",
        "\n",
        "\ty1 = h.history['val_accuracy']\n",
        "\ty2 = h.history['accuracy']\n",
        "\n",
        "\t_ = plt.title('Model Results', family='Arial', fontsize=12)\n",
        "\n",
        "\t_ = plt.plot(y1, \n",
        "\t\tcolor='blue', linewidth=1.5, marker='D', markersize=5,\n",
        "\t\tlabel='Validation acc.')\n",
        "\t_ = plt.plot(y2, \n",
        "\t\tcolor='#9999FF', linewidth=1.5, marker='D', markersize=5,\n",
        "\t\tlabel='Training acc.')\n",
        "\n",
        "\t_ = plt.xlabel('Epochs', family='Arial', fontsize=10)\n",
        "\t_ = plt.ylabel('Score', family='Arial', fontsize=10)\n",
        "\n",
        "\t_ = plt.yticks(np.arange(0., 1.25, 0.1),\n",
        "\t\t\t\t   family='Arial', fontsize=10)\n",
        "\n",
        "\tif len(h.history['accuracy']) < 51:\n",
        "\t\t_ = plt.xticks(np.arange(0, len(h.history['accuracy']), 1),\n",
        "\t\t\t\t\t   family='Arial', fontsize=10)\n",
        "\n",
        "\t_ = plt.ylim((0., 1.))\n",
        "\n",
        "\t_ = plt.fill_between(np.arange(0, len(h.history['accuracy']), 1),\n",
        "\t\t\t\t\t\t h.history['accuracy'], 0,\n",
        "\t\t\t\t\t\t color = '#cccccc', alpha=0.5)\n",
        "\n",
        "\t_ = plt.grid(which='major', color='#cccccc', linewidth=0.5)\n",
        "\t_ = plt.legend(loc='best', shadow=True)\n",
        "\t_ = plt.margins(0.02)\n",
        "\n",
        "\t_ = plt.show()\n",
        "\n",
        "\t# Plot #2\n",
        "\t_ = plt.clf()\n",
        "\n",
        "\t_ = plt.plot(h.history['val_loss'], \n",
        "\t\tcolor='red', linewidth=1.5, marker='D', markersize=5,\n",
        "\t\tlabel='Validation loss')\n",
        "\t_ = plt.plot(h.history['loss'], \n",
        "\t\tcolor='#FF7F7F', linewidth=1.5, marker='D', markersize=5,\n",
        "\t\tlabel='Loss')\n",
        "\n",
        "\t_ = plt.xlabel('Epochs', family='Arial', fontsize=10)\n",
        "\t_ = plt.ylabel('Loss score', family='Arial', fontsize=10)\n",
        "\n",
        "\tif len(h.history['accuracy']) < 51:\n",
        "\t\t_ = plt.xticks(np.arange(0, len(h.history['accuracy']), 1),\n",
        "\t\t\t\t\t   family='Arial', fontsize=10)\n",
        "\t_ = plt.yticks(family='Arial', fontsize=10)\n",
        "\n",
        "\t_ = plt.grid(which='major', color='#cccccc', linewidth=0.5)\n",
        "\t_ = plt.legend(loc='best', shadow=True)\n",
        "\t_ = plt.margins(0.02)\n",
        "\n",
        "\t_ = plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWRT15zCgvZL"
      },
      "source": [
        "plot_model_result(h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY1jO4gyb-L2"
      },
      "source": [
        "## Loading the model for further using "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiyqWP30f3CJ"
      },
      "source": [
        "# Save the Model Weights\n",
        "model.save_weights('model_100_eopchs_adam_20191030_01.h5')\n",
        "\n",
        "# Save the Model to JSON\n",
        "model_json = model.to_json()\n",
        "with open('model_adam_20191030_01.json', 'w') as json_file:\n",
        "    json_file.write(model_json)\n",
        "    \n",
        "print('Model saved to the disk.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGn25FwMf8yz"
      },
      "source": [
        "# Load saved model and its weights\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.python.framework import ops\n",
        "ops.reset_default_graph()\n",
        "import h5py \n",
        "from PIL import Image\n",
        "import PIL\n",
        "from vb100_utils import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74Nd2b-AgFjn"
      },
      "source": [
        "print('h5py version is {}'.format(h5py.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuHd4JkWof8l"
      },
      "source": [
        "# Get the architecture of CNN\n",
        "json_file = open('model_adam.json')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# Get weights into the model\n",
        "loaded_model.load_weights('model_100_eopchs_adam_20190807.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQQBX9geohQo"
      },
      "source": [
        "'''\n",
        "Here I will simulate what will happen during deployment on a cloud.\n",
        "Reading a given image, preparing it for CNN evaluation and make\n",
        "a predictions with a returned class from a dictionary that has\n",
        "been used for training.\n",
        "'''\n",
        "\n",
        "# Define optimizer and run\n",
        "opt = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
        "loaded_model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='rmsprop')\n",
        "'''\n",
        "Important Note! For this block optimizer is entered manualy as Tensorflow object.\n",
        "For future, need to change it for include it as variable with full set of\n",
        "parameters as Tensorflow variable.\n",
        "\n",
        "'''\n",
        "IMG = Image.open('Pneumonia-X-Rays-of-Human-Lungs-AI-project/data/val/BACTERIA/person1950_bacteria_4881.jpeg')\n",
        "print(type(IMG))\n",
        "IMG = IMG.resize((342, 257))\n",
        "IMG = np.array(IMG)\n",
        "print('po array = {}'.format(IMG.shape))\n",
        "IMG = np.true_divide(IMG, 255)\n",
        "IMG = IMG.reshape(1, 342, 257, 1)\n",
        "print(type(IMG), IMG.shape)\n",
        "\n",
        "predictions = loaded_model.predict(IMG)\n",
        "\n",
        "print(loaded_model)\n",
        "predictions_c = loaded_model.predict_classes(IMG)\n",
        "print(predictions, predictions_c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm9nVrEBp_BO"
      },
      "source": [
        "classes = {'TRAIN': ['BACTERIA', 'NORMAL', 'VIRUS'],\n",
        "           'VALIDATION': ['BACTERIA', 'NORMAL'],\n",
        "           'TEST': ['BACTERIA', 'NORMAL', 'VIRUS']}\n",
        "\n",
        "predicted_class = classes['TRAIN'][predictions_c[0]]\n",
        "print('We think that is {}.'.format(predicted_class.lower()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFSlEt9umica"
      },
      "source": [
        "# !pip install gevent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOdhJnCqm0RU"
      },
      "source": [
        "# !pip install flask_ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8ixgTD2QNcw"
      },
      "source": [
        "MODEL_ARCHITECTURE = 'model_adam.json'\n",
        "MODEL_WEIGHTS = 'model_100_eopchs_adam_20190807.h5'\n",
        "\n",
        "# Load the model from external files\n",
        "json_file = open(MODEL_ARCHITECTURE)\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "model = model_from_json(loaded_model_json)\n",
        "\n",
        "# Get weights into the model\n",
        "model.load_weights(MODEL_WEIGHTS)\n",
        "# ::: MODEL FUNCTIONS :::\n",
        "def model_predict(img_path, model):\n",
        "\t'''\n",
        "\t\tArgs:\n",
        "\t\t\t-- img_path : an URL path where a given image is stored.\n",
        "\t\t\t-- model : a given Keras CNN model.\n",
        "\t'''\n",
        "\tIMG = image.load_img(img_path).convert('L')\n",
        "\tprint(type(IMG))\n",
        "\n",
        "\t# Pre-processing the image\n",
        "\tIMG_ = IMG.resize((257, 342))\n",
        "\tprint(type(IMG_))\n",
        "\tIMG_ = np.asarray(IMG_)\n",
        "\tprint(IMG_.shape)\n",
        "\tIMG_ = np.true_divide(IMG_, 255)\n",
        "\tIMG_ = IMG_.reshape(1, 342, 257, 1)\n",
        "\tprint(type(IMG_), IMG_.shape)\n",
        "\n",
        "\tprint(model)\n",
        "\n",
        "\tmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='rmsprop')\n",
        "\tprediction = model.predict_classes(IMG_)\n",
        "\treturn prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_su7SDTDQWMI"
      },
      "source": [
        "prediction = model_predict('Pneumonia-X-Rays-of-Human-Lungs-AI-project/data/train/VIRUS/person1000_virus_1681.jpeg', model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KGdED70Q_mD"
      },
      "source": [
        "predicted_class = classes['TRAIN'][prediction[0]]\n",
        "predicted_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hmmyja-ZcH33"
      },
      "source": [
        "## Flask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhrck9QXeUbK"
      },
      "source": [
        "# Import modules and packages\n",
        "# Flask utils\n",
        "from flask import Flask, redirect, url_for, request, render_template\n",
        "from werkzeug.utils import secure_filename\n",
        "from gevent.pywsgi import WSGIServer\n",
        "from flask_ngrok import run_with_ngrok\n",
        "# Import Keras dependencies\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.python.framework import ops\n",
        "ops.reset_default_graph()\n",
        "from keras.preprocessing import image\n",
        "# Import other dependecies\n",
        "import numpy as np\n",
        "import h5py\n",
        "from PIL import Image\n",
        "import PIL\n",
        "import os\n",
        "#Flask App Engine\n",
        "# Define a Flask app\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)   \n",
        "# ::: Prepare Keras Model :::\n",
        "# Model files\n",
        "MODEL_ARCHITECTURE = 'model_adam.json'\n",
        "MODEL_WEIGHTS = 'model_100_eopchs_adam_20190807.h5'\n",
        "\n",
        "# Load the model from external files\n",
        "json_file = open(MODEL_ARCHITECTURE)\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "model = model_from_json(loaded_model_json)\n",
        "\n",
        "# Get weights into the model\n",
        "model.load_weights(MODEL_WEIGHTS)\n",
        "# ::: MODEL FUNCTIONS :::\n",
        "def model_predict(img_path, model):\n",
        "\t'''\n",
        "\t\tArgs:\n",
        "\t\t\t-- img_path : an URL path where a given image is stored.\n",
        "\t\t\t-- model : a given Keras CNN model.\n",
        "\t'''\n",
        "\tIMG = image.load_img(img_path).convert('L')\n",
        "\tprint(type(IMG))\n",
        "\n",
        "\t# Pre-processing the image\n",
        "\tIMG_ = IMG.resize((257, 342))\n",
        "\tprint(type(IMG_))\n",
        "\tIMG_ = np.asarray(IMG_)\n",
        "\tprint(IMG_.shape)\n",
        "\tIMG_ = np.true_divide(IMG_, 255)\n",
        "\tIMG_ = IMG_.reshape(1, 342, 257, 1)\n",
        "\tprint(type(IMG_), IMG_.shape)\n",
        "\n",
        "\tprint(model)\n",
        "\n",
        "\tmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='rmsprop')\n",
        "\tprediction = model.predict_classes(IMG_)\n",
        "\treturn prediction\n",
        "# ::: FLASK ROUTES\n",
        "@app.route('/', methods=['GET'])\n",
        "def index():\n",
        "\t# Main Page\n",
        "\treturn render_template('index.html')\n",
        "@app.route('/predict', methods=['GET', 'POST'])\n",
        "def upload():\n",
        "\t# Constants:\n",
        "\tclasses = {'TRAIN': ['BACTERIA', 'NORMAL', 'VIRUS'],\n",
        "\t           'VALIDATION': ['BACTERIA', 'NORMAL'],\n",
        "\t           'TEST': ['BACTERIA', 'NORMAL', 'VIRUS']}\n",
        "\n",
        "\tif request.method == 'POST':\n",
        "\n",
        "\t\t# Get the file from post request\n",
        "\t\tf = request.files['file']\n",
        "\n",
        "\t\t# Save the file to ./uploads\n",
        "\t\tbasepath = os.path.dirname(__file__)\n",
        "\t\tfile_path = os.path.join(\n",
        "\t\t\tbasepath, 'uploads', secure_filename(f.filename))\n",
        "\t\tf.save(file_path)\n",
        "\n",
        "\t\t# Make a prediction\n",
        "\t\tprediction = model_predict('Pneumonia-X-Rays-of-Human-Lungs-AI-project/data/train/VIRUS/person1000_virus_1681.jpeg', model)\n",
        "\n",
        "\t\tpredicted_class = classes['TRAIN'][prediction[0]]\n",
        "\t\tprint('We think that is {}.'.format(predicted_class.lower()))\n",
        "\n",
        "\t\treturn str(predicted_class).lower()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\tapp.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsMGs4BiI0Ke"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}